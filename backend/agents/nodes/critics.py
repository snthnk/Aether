import asyncio
import os
import re
from llm.llms import llm
from typing import Dict, List, Any, Callable, Awaitable
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.prompts import ChatPromptTemplate
from agents.prompts import (
    INNOVATOR_PROMPT_TEMPLATE, PRAGMATIST_PROMPT_TEMPLATE, STRATEGIST_PROMPT_TEMPLATE,
    SYNTHESIZER_PROMPT_TEMPLATE, SEARCH_QUERY_GENERATOR_PROMPT)
from agents.classes import Hypothesis
from agents.classes import GraphState
from agents.nodes.searcher import make_research


SearchToolFunc = Callable[[str], Awaitable[List[Dict[str, Any]]]]

def _parse_searcher_report(report_text: str) -> List[Dict[str, str]]:
        if not report_text or "–Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å—Ç–∞—Ç—å–∏" in report_text:
            return []
        articles_raw = report_text.split("\n---\n")
        parsed_articles = []
        for article_block in articles_raw:
            if "### üìñ –°—Ç–∞—Ç—å—è:" not in article_block:
                continue
            title_match = re.search(r"### üìñ –°—Ç–∞—Ç—å—è:\s*(.*)", article_block)
            summary_match = re.search(r"\*\*–†–µ–∑—é–º–µ:\*\*\n(.*)", article_block, re.DOTALL)
            title = title_match.group(1).strip() if title_match else "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"
            summary = summary_match.group(1).strip() if summary_match else "–†–µ–∑—é–º–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"
            parsed_articles.append({"title": title, "summary": summary})
        return parsed_articles


async def run_search_agent_as_tool(query: str) -> List[Dict[str, Any]]:

    searcher_initial_state = GraphState(
        user_question=query,
        last_reasoning="",
        search_history=[],
        hypotheses_and_critics=[],
        last_goto="",
        search_system_input="",
        current_search_request=None,
        papers=[],
        summaries=[],
        validated_summaries=[],
        final_report=None,
        error=None,
        search_cycles=0
    )

    report_text, _ = await asyncio.to_thread(
        make_research,
        query,
        searcher_initial_state
    )

    print("--- [TOOL: Search Agent] –ê–≥–µ–Ω—Ç-–ø–æ–∏—Å–∫–æ–≤–∏–∫ –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É. –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç—á–µ—Ç–∞... ---")
    structured_results = _parse_searcher_report(report_text)
    print(f"--- [TOOL: Search Agent] –û—Ç—á–µ—Ç —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω. –ù–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: {len(structured_results)}. ---")
    return structured_results


class CritiquePanel:
        _SEARCH_QUERY_GENERATOR_PROMPT = SEARCH_QUERY_GENERATOR_PROMPT
        _INNOVATOR_PROMPT_TEMPLATE = INNOVATOR_PROMPT_TEMPLATE
        _PRAGMATIST_PROMPT_TEMPLATE = PRAGMATIST_PROMPT_TEMPLATE
        _STRATEGIST_PROMPT_TEMPLATE = STRATEGIST_PROMPT_TEMPLATE
        _SYNTHESIZER_PROMPT_TEMPLATE = SYNTHESIZER_PROMPT_TEMPLATE

        def __init__(self, llm: BaseChatModel, search_tool: SearchToolFunc):
            self.llm = llm
            self.search_tool = search_tool

        async def _run_critic(self, critic_name: str, prompt_template: str, **kwargs) -> str:
            prompt = ChatPromptTemplate.from_template(prompt_template)
            chain = prompt | self.llm
            response = await chain.ainvoke(kwargs)
            return response.content

        async def _run_innovator(self, hypothesis: str, source_materials_text: str) -> str:
            print("-> [–ù–æ–≤–∞—Ç–æ—Ä] –ó–∞–ø—É—â–µ–Ω.")
            query_gen_prompt = self._SEARCH_QUERY_GENERATOR_PROMPT.format(hypothesis_text=hypothesis)
            generated_query = (await self.llm.ainvoke(query_gen_prompt)).content.strip()

            search_results_list = await self.search_tool(generated_query)

            search_results_text = "\n\n".join([f"- {res['title']}:\n  {res.get('summary', 'N/A')}" for res in
                                               search_results_list]) if search_results_list else "–í–Ω–µ—à–Ω–∏–π –ø–æ–∏—Å–∫ –Ω–µ –¥–∞–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."

            critique = await self._run_critic(
                "–ù–æ–≤–∞—Ç–æ—Ä",
                self._INNOVATOR_PROMPT_TEMPLATE,
                hypothesis_text=hypothesis,
                source_materials=source_materials_text,
                search_results=search_results_text
            )

            print("-> [–ù–æ–≤–∞—Ç–æ—Ä] –û—Ç–∑—ã–≤ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω.")
            asyncio.sleep(4)
            return critique

        async def _run_pragmatist(self, hypothesis: str) -> str:
            print("-> [–ü—Ä–∞–≥–º–∞—Ç–∏–∫] –ó–∞–ø—É—â–µ–Ω.")
            critique = await self._run_critic("–ü—Ä–∞–≥–º–∞—Ç–∏–∫", self._PRAGMATIST_PROMPT_TEMPLATE, hypothesis_text=hypothesis)
            print("-> [–ü—Ä–∞–≥–º–∞—Ç–∏–∫] –û—Ç–∑—ã–≤ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω.")
            asyncio.sleep(4)
            return critique

        async def _run_strategist(self, hypothesis: str) -> str:
            print("-> [–°—Ç—Ä–∞—Ç–µ–≥] –ó–∞–ø—É—â–µ–Ω.")
            critique = await self._run_critic("–°—Ç—Ä–∞—Ç–µ–≥", self._STRATEGIST_PROMPT_TEMPLATE, hypothesis_text=hypothesis)
            print("-> [–°—Ç—Ä–∞—Ç–µ–≥] –û—Ç–∑—ã–≤ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω.")
            asyncio.sleep(4)
            return critique

        async def run_full_analysis(self, hypothesis: str, source_materials: List[Dict[str, Any]]) -> Dict[str, str]:
            print(f"\n===== –ù–ê–ß–ê–õ–û –ê–ù–ê–õ–ò–ó–ê –ì–ò–ü–û–¢–ï–ó–´ =====\n–ì–∏–ø–æ—Ç–µ–∑–∞: \"{hypothesis[:100]}...\"")
            source_materials_text = "\n\n".join([f"- {s['title']}:\n  {s.get('summary', 'N/A')}" for s in
                                                 source_materials]) if source_materials else "–ò—Å—Ö–æ–¥–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã."
            innovator_task = self._run_innovator(hypothesis, source_materials_text)
            pragmatist_task = self._run_pragmatist(hypothesis)
            strategist_task = self._run_strategist(hypothesis)
            innovator_result, pragmatist_result, strategist_result = await asyncio.gather(
                innovator_task, pragmatist_task, strategist_task
            )
            print("-> [–°–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä] –ó–∞–ø—É—â–µ–Ω.")
            final_synthesis = await self._run_critic(
                "–°–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä", self._SYNTHESIZER_PROMPT_TEMPLATE,
                hypothesis_text=hypothesis, innovator_critique=innovator_result,
                pragmatist_critique=pragmatist_result, strategist_critique=strategist_result
            )
            print("-> [–°–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä] –ò—Ç–æ–≥–æ–≤–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ.")
            print("===== –ê–ù–ê–õ–ò–ó –ì–ò–ü–û–¢–ï–ó–´ –ó–ê–í–ï–†–®–ï–ù =====\n")
            return {
                "innovator": innovator_result, "pragmatist": pragmatist_result,
                "strategist": strategist_result, "final": final_synthesis
            }


async def _critique_logic(state: GraphState) -> dict:
        print("--- NODE: Critique Panel ---")

        panel = CritiquePanel(llm=llm, search_tool=run_search_agent_as_tool)

        all_hypotheses_versions = state['hypotheses_and_critics']
        print(len(all_hypotheses_versions))

        if not all_hypotheses_versions:
            print("--- [Critique Panel] –ù–µ—Ç –≤–µ—Ä—Å–∏–π –≥–∏–ø–æ—Ç–µ–∑ –¥–ª—è –∫—Ä–∏—Ç–∏–∫–∏. –ü—Ä–æ–ø—É—Å–∫–∞—é —à–∞–≥. ---")
            return {}

        latest_hypotheses_list = all_hypotheses_versions[-1]

        search_history = state['search_history']
        source_materials = []
        if search_history:
            last_search = search_history[-1]
            source_materials = getattr(last_search, 'results', [])

        tasks, hypotheses_to_critique = [], []
        for hyp in latest_hypotheses_list:
            if not hyp.critique:
                tasks.append(panel.run_full_analysis(hyp.formulation, source_materials))
                hypotheses_to_critique.append(hyp)

        if not tasks:
            print("--- [Critique Panel] –í –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤–µ—Ä—Å–∏–∏ –Ω–µ—Ç –Ω–æ–≤—ã—Ö –≥–∏–ø–æ—Ç–µ–∑ –¥–ª—è –∫—Ä–∏—Ç–∏–∫–∏. –ü—Ä–æ–ø—É—Å–∫–∞—é —à–∞–≥. ---")
            return {}

        print(f"--- [Critique Panel] –û—Ç–ø—Ä–∞–≤–ª—è—é {len(tasks)} –≥–∏–ø–æ—Ç–µ–∑(—ã) –Ω–∞ –∞–Ω–∞–ª–∏–∑... ---")
        critique_results = await asyncio.gather(*tasks)

        for hyp, critique_dict in zip(hypotheses_to_critique, critique_results):
            final_critique = critique_dict.get('final', '–û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏—Ç–æ–≥–æ–≤—É—é –∫—Ä–∏—Ç–∏–∫—É.')
            hyp.critique = final_critique
            print(f"-> [Critique Panel] –î–æ–±–∞–≤–ª–µ–Ω –æ—Ç–∑—ã–≤ –¥–ª—è –≥–∏–ø–æ—Ç–µ–∑—ã: '{hyp.formulation[:50]}...'")

        state['hypotheses_and_critics'] = all_hypotheses_versions
        return {"hypotheses_and_critics": all_hypotheses_versions}


def critique_node(state: GraphState) -> dict:
        if os.name == 'nt':
            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
        return asyncio.run(_critique_logic(state))


if __name__ == '__main__':
        from backend.agents.classes import SearchRequest

        print("--- [TEST RUN] –ó–∞–ø—É—Å–∫–∞—é –∞–≤—Ç–æ–Ω–æ–º–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É —É–∑–ª–∞ –∫—Ä–∏—Ç–∏–∫–∏... ---")

        # 1. –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –≥–∏–ø–æ—Ç–µ–∑—ã, –∏–º–∏—Ç–∏—Ä—É—è —Å—Ç—Ä—É–∫—Ç—É—Ä—É List[List[...]]
        # –ü–µ—Ä–≤–∞—è –≤–µ—Ä—Å–∏—è, —É–∂–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è
        version_1 = [
            Hypothesis(
                formulation="–°—Ç–∞—Ä–∞—è –≥–∏–ø–æ—Ç–µ–∑–∞, –∫–æ—Ç–æ—Ä–∞—è —É–∂–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞.",
                critique="–≠—Ç–æ —É–∂–µ –±—ã–ª–æ —Å–¥–µ–ª–∞–Ω–æ –≤ 2020 –≥–æ–¥—É.",
                is_approved=False
            )
        ]
        # –í—Ç–æ—Ä–∞—è, –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è. –ó–¥–µ—Å—å –µ—Å—Ç—å –Ω–∞–¥ —á–µ–º –ø–æ—Ä–∞–±–æ—Ç–∞—Ç—å.
        version_2 = [
            Hypothesis(
                formulation="RL-–∞–≥–µ–Ω—Ç, –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–∞–µ–º—ã–π –∑–∞ —Å–æ–∑–¥–∞–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏–π —Å—Ä–µ–¥—ã, –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö —Å–ª–æ–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å—Å—è –≤ –∏—Å—Ö–æ–¥–Ω–æ–µ, –±—É–¥–µ—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –º–∏—Ä —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ, —á–µ–º –∞–≥–µ–Ω—Ç, —É–ø—Ä–∞–≤–ª—è–µ–º—ã–π —Ç–æ–ª—å–∫–æ –ª—é–±–æ–ø—ã—Ç—Å—Ç–≤–æ–º.",
                critique="",  # <-- –ö—Ä–∏—Ç–∏–∫–∏ –Ω–µ—Ç, –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å
                is_approved=False
            ),
            Hypothesis(
                formulation="–≠—Ç–∞ –≥–∏–ø–æ—Ç–µ–∑–∞ —É–∂–µ –∏–º–µ–µ—Ç –∫—Ä–∏—Ç–∏–∫—É –∏ –µ–µ —Ç—Ä–æ–≥–∞—Ç—å –Ω–µ –Ω–∞–¥–æ.",
                critique="–ö—Ä–∞—Ç–∫–∏–π –æ—Ç–∑—ã–≤.",  # <-- –ö—Ä–∏—Ç–∏–∫–∞ –µ—Å—Ç—å, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º
                is_approved=False
            )
        ]

        # 2. –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –∏—Å—Ç–æ—Ä–∏—é –ø–æ–∏—Å–∫–∞
        test_search_request = SearchRequest(
            input_query="RL agent exploration",
            search_queries=["RL irreversible states"],
            results=[{"title": "Empowerment - An Introduction", "summary": "–û–±—Å—É–∂–¥–∞–µ—Ç—Å—è –∫–æ–Ω—Ü–µ–ø—Ü–∏—è empowerment."}]
        )

        # 3. –°–æ–±–∏—Ä–∞–µ–º –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ, –°–û–û–¢–í–ï–¢–°–¢–í–£–Æ–©–ï–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø–ú
        test_state = GraphState(
            user_question="RL agents for exploration",
            last_reasoning="Formulator created a new version of hypotheses.",
            # –í–∫–ª–∞–¥—ã–≤–∞–µ–º –Ω–∞—à—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É "—Å–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤"
            hypotheses_and_critics=[version_1, version_2],
            search_history=[test_search_request],
            last_goto="critique"
        )

        print("\n--- [TEST RUN] –ù–ê–ß–ê–õ–¨–ù–û–ï –°–û–°–¢–û–Ø–ù–ò–ï (–ü–û–°–õ–ï–î–ù–Ø–Ø –í–ï–†–°–ò–Ø): ---")
        for hyp in test_state['hypotheses_and_critics'][-1]:
            print(f"-> {hyp.formulation[:30]}... | –ö—Ä–∏—Ç–∏–∫–∞: '{hyp.critique}'")

        # 4. –ó–∞–ø—É—Å–∫–∞–µ–º —É–∑–µ–ª –∫—Ä–∏—Ç–∏–∫–∏
        print("\n--- [TEST RUN] >>> –ó–ê–ü–£–°–ö critique_node() <<< ---")
        final_update = critique_node(test_state)
        print("--- [TEST RUN] >>> –ó–ê–í–ï–†–®–ï–ù–ò–ï critique_node() <<< ---\n")

        # 5. –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        updated_versions = final_update.get('hypotheses_and_critics', [])
        print("\n--- [TEST RUN] –ò–¢–û–ì–û–í–û–ï –°–û–°–¢–û–Ø–ù–ò–ï (–ü–û–°–õ–ï–î–ù–Ø–Ø –í–ï–†–°–ò–Ø): ---")
        if updated_versions:
            for hyp in updated_versions[-1]:
                print(f"-> {hyp.formulation[:30]}... | –ö—Ä–∏—Ç–∏–∫–∞: '{hyp.critique}'")
        else:
            print("–û—à–∏–±–∫–∞: —É–∑–µ–ª –Ω–µ –≤–µ—Ä–Ω—É–ª –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")

        query = 'Rl agents'
        hyp = Hypothesis(
                formulation="RL-–∞–≥–µ–Ω—Ç, –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–∞–µ–º—ã–π –∑–∞ —Å–æ–∑–¥–∞–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏–π —Å—Ä–µ–¥—ã, –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö —Å–ª–æ–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å—Å—è –≤ –∏—Å—Ö–æ–¥–Ω–æ–µ, –±—É–¥–µ—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –º–∏—Ä —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ, —á–µ–º –∞–≥–µ–Ω—Ç, —É–ø—Ä–∞–≤–ª—è–µ–º—ã–π —Ç–æ–ª—å–∫–æ –ª—é–±–æ–ø—ã—Ç—Å—Ç–≤–æ–º.",
                critique="",
                is_approved=False
            )

        inputs = GraphState(
                user_question=query,
                last_reasoning="",
                last_goto="",
                current_search_request=None,
                hypotheses_and_critics=[]
            )

        inputs.hypotheses_and_critics.append([hyp])
